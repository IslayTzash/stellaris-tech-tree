#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Convert .dds files in the Stellaris main folder and mod folders to .png files that can
be easily handled by a webserver.

It should be run prior to parse.py for each mod.   The parse.py will use the
img/remaps.json file generated by this script to dedupe some of the icon files.

self.single_files contains some corrections for the current Stellaris releases and
latest new horizons mod as of January 2, 2022.

This script requires the python Pillow graphics library.
"""

import json
import re

from configuration import Configuration
from os import listdir, path
from PIL import Image

# Define dictionary keys in one location
DEDUPE = 'dedupe'
OUT_NAME = 'out_name'

# Set true for verbose logging to the console
VERBOSE = False

class ImageConverter:

    def __init__(self):
        self.config = Configuration()    
        self.outdir = path.join('public', self.config.mod, 'img')
        self.subdirs = {
            'technologies': { DEDUPE: True },
            'resources': {  },
            'jobs': {  }
        }
        self.single_files = {
            # Vanilla icons with special handling
            'pop_job.dds': 'job.png',
            'fleet_size_icon.dds': 'fleet_size_icon.png',
            path.join('ship_stats', 'hit_points.dds') : 'ship_stats_hitpoints.png',
            path.join('text_icons', 'text_icon_tile_blocker.dds') : 'blocker.png',
            path.join('resources', 'society_research.dds') : 'society.png',
            path.join('resources', 'physics_research.dds') : 'physics.png',
            path.join('resources', 'engineering_research.dds') : 'engineering.png',
            path.join('technologies', 'tech_space_construction.dds') : 't_space_construction.png',
            # New Horizons icons with special handling
            'planet.dds': 'planet.png',
            path.join('resources', 'sr_dilithium_processed.dds') : 'dil_proc.png',
        }
        self.hashes = {}
        self.remaps = {}

    def process_one_file(self, in_file, out_file, should_dedupe):
        if not path.isfile(in_file) or in_file.lower().endswith('_grey.dds') or in_file.lower().endswith('_large.dds'):
            # ignoring subdirectories and special files
            return
        if VERBOSE:
            print(in_file)
        f = path.basename(path.normpath(out_file)).replace('.png', '')
        try:
            with Image.open(in_file) as im:
                if should_dedupe:
                    hash = list(im.getdata())
                    for k, v in self.hashes.items():
                        if (v == hash):
                            hash = None
                            self.remaps[f] = k
                            if VERBOSE:
                                print('Skipped {0} it is the same as {1}'.format(f,k))
                            break
                    if hash is None:
                        return
                else:
                    # Maintain some value just for the end of run file count
                    hash = in_file
                self.hashes[f] = hash
                im.save(out_file)
                if VERBOSE:
                    print('Saved {0}'.format(out_file))
                if f.startswith('sr_'):
                    no_sr = re.sub(r'([/\\])sr_', r'\1', out_file)
                    im.save(no_sr)
                    print('Saved duplicate without sr_ prefix as {0}'.format(no_sr))
        except Exception as e:
            print("Error converting {0} to {1}: {2}".format(in_file, out_file, e))

    def run(self):
        for directory in self.config.directories:
            for subdir, subdir_options in self.subdirs.items():
                in_dir = path.join(directory, 'gfx', 'interface', 'icons', subdir)
                if not path.exists(in_dir):
                    print('Ignoring directory {0}'.format(in_dir))
                    continue
                do_dedupe = DEDUPE in subdir_options and subdir_options[DEDUPE]
                for f in listdir( in_dir ):
                    self.process_one_file(path.join(in_dir, f), path.join(self.outdir, f.replace('.dds', '.png')), do_dedupe)

            for in_file, out_file in self.single_files.items():
                in_file = path.join(directory, 'gfx', 'interface', 'icons', in_file)
                out_file = path.join(self.outdir, out_file)
                # Any icon in a technologies/ folder can be de-duped
                self.process_one_file(in_file, out_file, 'technologies' in in_file)
                if VERBOSE and path.exists(in_file):
                    print("Converted {0} => {1}".format(in_file, out_file))

        with open(path.join(self.outdir, 'remaps.json'), 'w') as fp:
            json.dump(self.remaps, fp, indent=4, sort_keys=True)

        print('Converted {0} files with {1} duplicates.'.format(len(self.hashes), len(self.remaps)))

if __name__ == '__main__':
    ImageConverter().run()